{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAExH/NZAfXPAC0UGiXaCt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fbdsfoa/AtvExtra/blob/master/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF-TIBqDOURJ",
        "outputId": "b39a157f-560a-471c-f903-046a2fb8d321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Feature1   Feature2  Feature3  Target\n",
            "0  37.454012   1.571459  6.420316       0\n",
            "1  95.071431  31.820521  0.841400       1\n",
            "2  73.199394  15.717799  1.616287       0\n",
            "3  59.865848  25.428535  8.985542       0\n",
            "4  15.601864  45.378324  6.064291       0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Definindo a semente para reprodutibilidade\n",
        "np.random.seed(42)\n",
        "\n",
        "# Número de amostras\n",
        "num_samples = 100\n",
        "\n",
        "# Criando features numéricas\n",
        "feature1 = np.random.rand(num_samples) * 100  # Feature 1: valores entre 0 e 100\n",
        "feature2 = np.random.rand(num_samples) * 50    # Feature 2: valores entre 0 e 50\n",
        "feature3 = np.random.rand(num_samples) * 10     # Feature 3: valores entre 0 e 10\n",
        "\n",
        "# Criando um target binário (0 ou 1) baseado em uma condição simples\n",
        "target = (feature1 + feature2 + feature3 > 100).astype(int)\n",
        "\n",
        "# Criando um DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'Feature1': feature1,\n",
        "    'Feature2': feature2,\n",
        "    'Feature3': feature3,\n",
        "    'Target': target\n",
        "})\n",
        "\n",
        "# Exibindo as primeiras linhas do dataset\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Separando as features e o target\n",
        "X = data[['Feature1', 'Feature2', 'Feature3']]\n",
        "y = data['Target']\n",
        "\n",
        "# Dividindo o dataset em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizando os dados\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Definindo a arquitetura da rede neural\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(X_train.shape[1],)),  # Camada de entrada\n",
        "    layers.Dense(64, activation='relu'),        # Primeira camada escondida com 64 neurônios e ReLU\n",
        "    layers.Dense(32, activation='relu'),        # Segunda camada escondida com 32 neurônios e ReLU\n",
        "    layers.Dense(1, activation='sigmoid')       # Camada de saída com ativação sigmoide\n",
        "])\n",
        "\n",
        "# Compilando o modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mean_squared_error',  # Usando MSE como função de perda\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Treinando o modelo\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=10, validation_split=0.2)\n",
        "\n",
        "# Avaliando o modelo\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Acurácia no conjunto de teste: {accuracy:.2f}')\n",
        "\n",
        "# Usando o modelo treinado para fazer previsões\n",
        "# Exemplo de novos dados (deve ter o mesmo formato que as features)\n",
        "novos_dados = pd.DataFrame({\n",
        "    'Feature1': [30, 70],\n",
        "    'Feature2': [10, 30],\n",
        "    'Feature3': [2, 5]\n",
        "})\n",
        "\n",
        "# Normalizando os novos dados usando o mesmo scaler\n",
        "novos_dados_normalizados = scaler.transform(novos_dados)\n",
        "\n",
        "# Fazendo previsões\n",
        "previsoes = model.predict(novos_dados_normalizados)\n",
        "\n",
        "# Convertendo as previsões para 0 ou 1\n",
        "previsoes_classes = (previsoes > 0.5).astype(int)\n",
        "\n",
        "# Exibindo as previsões\n",
        "for i, previsao in enumerate(previsoes_classes):\n",
        "    print(f'Amostra {i + 1}: Previsão = {previsao[0]} (0 = Classe Negativa, 1 = Classe Positiva)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJSY5_QiVPsn",
        "outputId": "50561bc5-87b2-4c1c-c89a-4e72ef1b9554"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.3944 - loss: 0.2680 - val_accuracy: 0.4375 - val_loss: 0.2779\n",
            "Epoch 2/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7127 - loss: 0.2291 - val_accuracy: 0.5000 - val_loss: 0.2600\n",
            "Epoch 3/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7435 - loss: 0.1987 - val_accuracy: 0.5625 - val_loss: 0.2452\n",
            "Epoch 4/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8184 - loss: 0.1723 - val_accuracy: 0.5625 - val_loss: 0.2331\n",
            "Epoch 5/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8209 - loss: 0.1735 - val_accuracy: 0.5625 - val_loss: 0.2207\n",
            "Epoch 6/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9064 - loss: 0.1192 - val_accuracy: 0.6250 - val_loss: 0.2124\n",
            "Epoch 7/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8646 - loss: 0.1213 - val_accuracy: 0.7500 - val_loss: 0.1986\n",
            "Epoch 8/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9152 - loss: 0.1044 - val_accuracy: 0.7500 - val_loss: 0.1860\n",
            "Epoch 9/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9277 - loss: 0.0954 - val_accuracy: 0.6875 - val_loss: 0.1750\n",
            "Epoch 10/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8795 - loss: 0.1049 - val_accuracy: 0.7500 - val_loss: 0.1625\n",
            "Epoch 11/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8846 - loss: 0.0951 - val_accuracy: 0.7500 - val_loss: 0.1524\n",
            "Epoch 12/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9398 - loss: 0.0727 - val_accuracy: 0.8125 - val_loss: 0.1444\n",
            "Epoch 13/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9465 - loss: 0.0637 - val_accuracy: 0.8125 - val_loss: 0.1383\n",
            "Epoch 14/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9169 - loss: 0.0748 - val_accuracy: 0.8125 - val_loss: 0.1322\n",
            "Epoch 15/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9454 - loss: 0.0702 - val_accuracy: 0.8125 - val_loss: 0.1247\n",
            "Epoch 16/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0553 - val_accuracy: 0.8750 - val_loss: 0.1191\n",
            "Epoch 17/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9622 - loss: 0.0672 - val_accuracy: 0.8750 - val_loss: 0.1124\n",
            "Epoch 18/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9915 - loss: 0.0447 - val_accuracy: 0.8750 - val_loss: 0.1087\n",
            "Epoch 19/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9842 - loss: 0.0535 - val_accuracy: 0.8750 - val_loss: 0.1029\n",
            "Epoch 20/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9940 - loss: 0.0424 - val_accuracy: 0.8750 - val_loss: 0.0989\n",
            "Epoch 21/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9884 - loss: 0.0431 - val_accuracy: 0.8750 - val_loss: 0.0962\n",
            "Epoch 22/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9684 - loss: 0.0435 - val_accuracy: 0.8750 - val_loss: 0.0921\n",
            "Epoch 23/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9842 - loss: 0.0500 - val_accuracy: 0.8750 - val_loss: 0.0905\n",
            "Epoch 24/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0361 - val_accuracy: 0.8750 - val_loss: 0.0879\n",
            "Epoch 25/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9915 - loss: 0.0422 - val_accuracy: 0.8750 - val_loss: 0.0852\n",
            "Epoch 26/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9842 - loss: 0.0403 - val_accuracy: 0.8750 - val_loss: 0.0837\n",
            "Epoch 27/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9842 - loss: 0.0431 - val_accuracy: 0.8750 - val_loss: 0.0824\n",
            "Epoch 28/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9780 - loss: 0.0431 - val_accuracy: 0.8750 - val_loss: 0.0798\n",
            "Epoch 29/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9884 - loss: 0.0417 - val_accuracy: 0.8750 - val_loss: 0.0789\n",
            "Epoch 30/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9655 - loss: 0.0387 - val_accuracy: 0.8750 - val_loss: 0.0765\n",
            "Epoch 31/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9884 - loss: 0.0370 - val_accuracy: 0.8750 - val_loss: 0.0754\n",
            "Epoch 32/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9884 - loss: 0.0300 - val_accuracy: 0.8750 - val_loss: 0.0745\n",
            "Epoch 33/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9884 - loss: 0.0326 - val_accuracy: 0.8750 - val_loss: 0.0744\n",
            "Epoch 34/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9915 - loss: 0.0266 - val_accuracy: 0.8750 - val_loss: 0.0728\n",
            "Epoch 35/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9780 - loss: 0.0294 - val_accuracy: 0.9375 - val_loss: 0.0708\n",
            "Epoch 36/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9961 - loss: 0.0243 - val_accuracy: 0.9375 - val_loss: 0.0701\n",
            "Epoch 37/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9780 - loss: 0.0376 - val_accuracy: 0.9375 - val_loss: 0.0673\n",
            "Epoch 38/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0350 - val_accuracy: 0.8750 - val_loss: 0.0679\n",
            "Epoch 39/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0319 - val_accuracy: 0.9375 - val_loss: 0.0667\n",
            "Epoch 40/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0226 - val_accuracy: 0.8750 - val_loss: 0.0675\n",
            "Epoch 41/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0272 - val_accuracy: 0.8750 - val_loss: 0.0671\n",
            "Epoch 42/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0257 - val_accuracy: 0.9375 - val_loss: 0.0653\n",
            "Epoch 43/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0259 - val_accuracy: 0.9375 - val_loss: 0.0639\n",
            "Epoch 44/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0226 - val_accuracy: 0.9375 - val_loss: 0.0641\n",
            "Epoch 45/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0221 - val_accuracy: 0.9375 - val_loss: 0.0630\n",
            "Epoch 46/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0267 - val_accuracy: 0.9375 - val_loss: 0.0619\n",
            "Epoch 47/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0251 - val_accuracy: 0.9375 - val_loss: 0.0609\n",
            "Epoch 48/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0210 - val_accuracy: 0.9375 - val_loss: 0.0612\n",
            "Epoch 49/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0233 - val_accuracy: 0.9375 - val_loss: 0.0617\n",
            "Epoch 50/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0250 - val_accuracy: 0.9375 - val_loss: 0.0610\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9500 - loss: 0.0375\n",
            "Acurácia no conjunto de teste: 0.95\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "Amostra 1: Previsão = 0 (0 = Classe Negativa, 1 = Classe Positiva)\n",
            "Amostra 2: Previsão = 1 (0 = Classe Negativa, 1 = Classe Positiva)\n"
          ]
        }
      ]
    }
  ]
}