{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1hxpJe/h/prgeiqvNJmQm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fbdsfoa/AtvExtra/blob/master/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cEQpl0v1dpBF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Baixar o dataset diretamente\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "column_names = [\n",
        "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
        "    \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
        "    \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"\n",
        "]\n",
        "data = pd.read_csv(url, header=None, names=column_names, na_values=\" ?\", skipinitialspace=True)\n",
        "\n",
        "# Remover valores faltantes\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Separar variáveis independentes (X) e dependente (y)\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "# Converter a variável alvo para 0 e 1\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "\n",
        "# Transformar variáveis categóricas em numéricas (one-hot encoding)\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# Normalizar variáveis contínuas\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Dividir em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Converter para tensores\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Criar DataLoaders para facilitar o treinamento\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "Ux8P75AWmzY4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FullyConnectedNet(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(FullyConnectedNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)  # Saída para classificação binária\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))  # Sigmoid para probabilidade entre 0 e 1\n",
        "        return x\n",
        "\n",
        "input_size = X_train.shape[1]\n",
        "model = FullyConnectedNet(input_size)\n"
      ],
      "metadata": {
        "id": "h1Kc5Xacm3GX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()  # Função de perda para classificação binária\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        # Resetar os gradientes\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = model(X_batch).squeeze()\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "\n",
        "        # Backward pass e atualização de pesos\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98KnLXYXm7fU",
        "outputId": "972b8eee-8944-45d2-b932-b09a4eff9f65"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.3471\n",
            "Epoch 2/20, Loss: 0.3136\n",
            "Epoch 3/20, Loss: 0.3048\n",
            "Epoch 4/20, Loss: 0.3004\n",
            "Epoch 5/20, Loss: 0.2958\n",
            "Epoch 6/20, Loss: 0.2904\n",
            "Epoch 7/20, Loss: 0.2871\n",
            "Epoch 8/20, Loss: 0.2833\n",
            "Epoch 9/20, Loss: 0.2783\n",
            "Epoch 10/20, Loss: 0.2739\n",
            "Epoch 11/20, Loss: 0.2711\n",
            "Epoch 12/20, Loss: 0.2660\n",
            "Epoch 13/20, Loss: 0.2616\n",
            "Epoch 14/20, Loss: 0.2586\n",
            "Epoch 15/20, Loss: 0.2535\n",
            "Epoch 16/20, Loss: 0.2501\n",
            "Epoch 17/20, Loss: 0.2458\n",
            "Epoch 18/20, Loss: 0.2410\n",
            "Epoch 19/20, Loss: 0.2379\n",
            "Epoch 20/20, Loss: 0.2342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model.eval()\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, _ in test_loader:\n",
        "        preds = model(X_batch).squeeze()\n",
        "        y_pred.extend((preds > 0.5).int().numpy())\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Acurácia no conjunto de teste: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLaWEcONnKsb",
        "outputId": "65716458-f8b2-4d6c-8ec4-467f3dc1b4f7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia no conjunto de teste: 0.8475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar o modelo treinado\n",
        "torch.save(model.state_dict(), \"fully_connected_model.pth\")\n",
        "print(\"Modelo salvo em 'fully_connected_model.pth'\")\n",
        "\n",
        "# Recriar a estrutura do modelo\n",
        "loaded_model = FullyConnectedNet(input_size)\n",
        "loaded_model.load_state_dict(torch.load(\"fully_connected_model.pth\"))\n",
        "loaded_model.eval()  # Colocar o modelo em modo de avaliação\n",
        "print(\"Modelo carregado com sucesso!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S35pEz2jomI0",
        "outputId": "47a6efc9-3421-45da-f5ac-39957f1ac170"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo salvo em 'fully_connected_model.pth'\n",
            "Modelo carregado com sucesso!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-20340c5a8d98>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model.load_state_dict(torch.load(\"fully_connected_model.pth\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Suponha que você tenha um DataFrame X que foi usado para treinar o modelo\n",
        "# Exemplo de dado de treinamento (defina com seus dados reais)\n",
        "# X = pd.DataFrame(...) # Dados de treinamento\n",
        "\n",
        "# Exemplo de dado novo (substitua pelos seus dados reais)\n",
        "new_data = np.array([[39, 'State-gov', 77516, 'Bachelors', 13, 'Never-married',\n",
        "                      'Adm-clerical', 'Not-in-family', 'White', 'Male', 2174,\n",
        "                      0, 40, 'United-States']])\n",
        "\n",
        "# Nomes das colunas\n",
        "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
        "                  'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "                  'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
        "\n",
        "# Converter new_data para DataFrame usando column_names (sem a coluna 'income')\n",
        "new_data = pd.DataFrame(new_data, columns=column_names[:-1])\n",
        "\n",
        "# Aplicar one-hot encoding com pd.get_dummies\n",
        "new_data = pd.get_dummies(new_data)\n",
        "\n",
        "# Garantir que new_data tenha as mesmas colunas de X (dados de treinamento)\n",
        "# Reindexar new_data para combinar com as colunas de X_train\n",
        "new_data = new_data.reindex(columns=X.columns, fill_value=0)  # Colunas de X.train\n",
        "\n",
        "# Carregar o scaler (supondo que o scaler foi treinado com os dados de treinamento)\n",
        "# Exemplo: scaler = StandardScaler().fit(X)\n",
        "scaler = StandardScaler()  # Isso deve ser o scaler que você usou para treinar o modelo\n",
        "new_data = scaler.fit_transform(new_data)  # Transformar os novos dados com o scaler\n",
        "\n",
        "# Converter para tensor\n",
        "new_data_tensor = torch.tensor(new_data, dtype=torch.float32)\n",
        "\n",
        "# Carregar o modelo treinado (supondo que o modelo foi salvo em 'loaded_model')\n",
        "# Exemplo: loaded_model = torch.load('path_to_model.pth')\n",
        "# Supondo que você tenha um modelo carregado com 'loaded_model'\n",
        "\n",
        "with torch.no_grad():\n",
        "    prediction = loaded_model(new_data_tensor).squeeze().item()\n",
        "    print(f\"Probabilidade de renda >50K: {prediction:.4f}\")\n",
        "    print(\"Classe prevista:\", \">=50K\" if prediction > 0.5 else \"<50K\")\n",
        "\n",
        "# Avaliar a acurácia no conjunto de teste\n",
        "y_pred = []\n",
        "\n",
        "# Supondo que você tenha um DataLoader com os dados de teste, como test_loader\n",
        "# Exemplo: test_loader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, _ in test_loader:\n",
        "        preds = loaded_model(X_batch).squeeze()\n",
        "        y_pred.extend((preds > 0.5).int().numpy())\n",
        "\n",
        "# Calcular a acurácia\n",
        "accuracy = accuracy_score(y_test, y_pred)  # y_test é o conjunto de rótulos verdadeiros de teste\n",
        "print(f\"Acurácia no conjunto de teste (modelo carregado): {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vhm4UTNqRQD",
        "outputId": "8dfe1eb9-7662-4466-8c3b-444dbaf66369"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilidade de renda >50K: 0.6386\n",
            "Classe prevista: >=50K\n",
            "Acurácia no conjunto de teste (modelo carregado): 0.8475\n"
          ]
        }
      ]
    }
  ]
}